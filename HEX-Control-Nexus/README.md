# HEX Control Nexus ğŸ”—

## Multi-Language Automation Hub

```
â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â•šâ–ˆâ–ˆâ–ˆâ•”â•     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•   â–ˆâ–ˆâ•”â–ˆâ–ˆâ•—     â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â•  
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•

HEX Control Nexus â€” Multi-Language Automation Hub
```

> **Ethics Reminder**: Use responsibly. Always check `robots.txt` and website terms. Do not collect personal or sensitive data without permission.

---

## ğŸ“‹ Project Overview

**HEX Control Nexus** is an advanced multi-language automation hub designed for web scraping, API automation, browser automation, and webhook management. Built with a focus on ethical use and compliance, this system integrates Python, Java, and Node.js components to provide a comprehensive automation solution.

### ğŸ”§ Key Features

- **Web Scraping**: Static (requests/BeautifulSoup) and dynamic (Puppeteer) scraping with robots.txt compliance
- **API Automation**: Async HTTP client with retry logic and circuit breaker pattern
- **Browser Automation**: Puppeteer tasks with screenshot capabilities
- **Webhooks**: Node.js webhook listener with job queue management
- **Scheduler**: CLI interface with daemon mode and configurable targets
- **Notifications**: Telegram, email, Slack/Discord support
- **Monitoring**: Structured JSON logging, real-time dashboard, health/metrics endpoints
- **Security**: Environment-based secrets management, graceful shutdown, retry policies

---

## ğŸš€ Quick Start

### Docker Deployment (Recommended)

```bash
docker-compose up --build
```

### Local Development

```bash
./scripts/setup.sh && python3 backend/python_core/automation.py --once --target demo
```

### Termux Environment

```bash
bash scripts/run.sh
```

---

## ğŸ“ Project Structure

```
HEX-Control-Nexus/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ python_core/
â”‚   â”œâ”€â”€ java_service/
â”‚   â””â”€â”€ node_webhooks/
â”œâ”€â”€ web_dashboard/
â”œâ”€â”€ config/
â”œâ”€â”€ database/
â”œâ”€â”€ scripts/
â”œâ”€â”€ tests/
â”œâ”€â”€ Dockerfile
â””â”€â”€ docker-compose.yml
```

---

## ğŸ› ï¸ Language â†’ Component Mapping

- **Python** (`backend/python_core`): Core automation, scrapers, notifier, SQLite access
- **Java** (`backend/java_service`): Spring Boot microservice with REST endpoints
- **Node.js** (`backend/node_webhooks`): Webhook listener, Puppeteer browser tasks
- **HTML/CSS/JS** (`web_dashboard`): Frontend dashboard with WebSocket for real-time logs
- **JSON/YAML** (`config`): All target definitions, selectors, endpoints, schedules
- **Bash** (`scripts`): Setup, run, and deployment scripts
- **SQLite** (`database`): Local storage for logs, job state, scraped data
- **Docker** (`Dockerfile`/`docker-compose.yml`): Containerization for all services

---

## ğŸ“– Documentation

### Configuration

The system is configured through JSON and YAML files in the `config/` directory:

- `config.json`: Main configuration with scraping targets
- `endpoints.yaml`: API endpoints and scheduling
- `schedule.yaml`: Task scheduling configuration

### CLI Usage

```bash
python backend/python_core/automation.py [OPTIONS]

Options:
  --target TEXT     Run specific target
  --config TEXT     Config file path
  --once            Run once and exit
  --daemon          Run in daemon mode
  --dry-run         Dry run without actually scraping
  --export TEXT     Export format (csv, jsonl, sqlite)
```

### Environment Variables

Copy `.env.example` to `.env` and configure your credentials:

```bash
cp .env.example .env
# Edit .env with your credentials
```

---

## ğŸ”’ Legal & Compliance

This system includes built-in compliance features:

- **robots.txt checking** by default (override with `--force`)
- **Data privacy considerations** and personal data handling guidelines
- **Terms of service compliance** framework
- **Acceptable use policies** documented in `LEGAL.md`

---

## ğŸ§ª Testing

Run all tests:

```bash
make test
```

Or run specific test suites:

```bash
make test-python
make test-node
```

---

## ğŸ“¦ Deployment Options

1. **Docker** (recommended): `docker-compose up --build`
2. **Local development**: `./scripts/setup.sh && python3 backend/python_core/automation.py --once --target demo`
3. **Termux environment**: `bash scripts/run.sh`

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Thanks to all contributors who have helped develop this automation hub
- Inspired by ethical web scraping and automation best practices

---

*Use responsibly. Always check robots.txt and website terms. Do not collect personal or sensitive data without permission.*